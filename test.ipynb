{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c458dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (4.50.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: evaluate in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (0.4.3)\n",
      "Collecting rouge_score\n",
      "  Using cached rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: filelock in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: absl-py in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: click in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abdoa\\anaconda3\\envs\\ml\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py): started\n",
      "  Building wheel for rouge_score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=25025 sha256=dfe5d94334fa7ad4d4e7b4eb333490b87aa70b20c77460e139d6fb7d7a2236bf\n",
      "  Stored in directory: c:\\users\\abdoa\\appdata\\local\\pip\\cache\\wheels\\1e\\19\\43\\8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers datasets  evaluate rouge_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e993e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# تحميل النموذج المحفوظ\n",
    "model_path = \"AraT5_finetuned_model\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47d108e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2633/2633 [00:00<00:00, 5790.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "dataset = {\"input_text\": [], \"target_text\": []}\n",
    "\n",
    "with open(\"unique_all.txt\", \"r\") as f:\n",
    "  lines = f.readlines()\n",
    "  for i in range(0, len(lines), 2):  # Step by 2 to get input and target\n",
    "    dataset[\"input_text\"].append(lines[i].strip())  \n",
    "    dataset[\"target_text\"].append(lines[i+1].strip())\n",
    "\n",
    "# تحويلها إلى Dataset خاص بـ Hugging Face\n",
    "train_dataset = Dataset.from_dict(dataset)\n",
    "\n",
    "# تحويل النصوص إلى Tokens\n",
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(examples[\"input_text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    targets = tokenizer(examples[\"target_text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76d00a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "\n",
    "arabert_prep = ArabertPreprocessor(\"aubmindlab/bert-base-arabertv02\")\n",
    "\n",
    "# Function to replace words with synonyms (example for Arabic)\n",
    "def synonym_replacement(text):\n",
    "    words = text.split()\n",
    "    if len(words) < 2:\n",
    "        return text\n",
    "    index = random.randint(0, len(words) - 1)\n",
    "    words[index] = arabert_prep.preprocess(words[index])  # Apply some transformation\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply augmentation\n",
    "augmented_input = [synonym_replacement(txt) for txt in dataset[\"input_text\"]]\n",
    "augmented_target = [synonym_replacement(txt) for txt in dataset[\"target_text\"]]\n",
    "\n",
    "# Add original + augmented data\n",
    "dataset[\"input_text\"].extend(augmented_input)\n",
    "dataset[\"target_text\"].extend(augmented_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f249342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume train_dataset is already loaded\n",
    "test_size = 0.1  # Allocate 10% for testing\n",
    "train_size = len(train_dataset) - int(test_size * len(train_dataset))\n",
    "\n",
    "# Split into train and test\n",
    "train_dataset, test_dataset = train_dataset.train_test_split(\n",
    "    train_size=train_size, test_size=int(test_size * len(train_dataset)), seed=42\n",
    ").values()\n",
    "\n",
    "# Now split the remaining train dataset into training and validation\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "eval_size = len(train_dataset) - train_size\n",
    "\n",
    "train_dataset, eval_dataset = train_dataset.train_test_split(\n",
    "    train_size=train_size, test_size=eval_size, seed=42\n",
    ").values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e468a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "الفلوس اللي كنت شايلها في الدولاب، واللابتوب بتاع ابني.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# اختبار النموذج مع نص جديد\n",
    "input_text =  \"ايه اللى اتسرق\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# توليد النص باستخدام النموذج المدرب\n",
    "output_tokens = model.generate(**inputs)\n",
    "output_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "print( output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93053e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=1)  # استخدم GPU إن أمكن\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for idx, example in enumerate(test_dataset):\n",
    "    input_text = f\"question: {example['input_text']} context: {example['target_text']}\"\n",
    "    output = qa_pipeline(input_text, max_length=100, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "    \n",
    "    predictions.append({\n",
    "        \"id\": str(idx),\n",
    "        \"prediction_text\": output\n",
    "    })\n",
    "    \n",
    "    references.append({\n",
    "        \"id\": str(idx),\n",
    "        \"answers\": [\n",
    "            {\n",
    "                \"text\": example[\"target_text\"],\n",
    "                \"answer_start\": 0  # مؤقتًا لو مش عندك مكان الإجابة في الـ context\n",
    "            }\n",
    "        ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31e039c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 8.745247148288973, 'f1': 38.56830961769148}\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "metric = load(\"squad\")\n",
    "results = metric.compute(predictions=predictions, references=references)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d0ccac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_text': 'هل عندك أي كاميرات مراقبة؟', 'target_text': 'للأسف لا.', 'input_ids': [1661, 3341, 918, 47089, 19976, 109673, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [10990, 126, 109566, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6f61fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.09378960709759188\n",
      "ROUGE-2: 0.06463878326996197\n",
      "ROUGE-L: 0.09378960709759188\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from evaluate import load\n",
    "\n",
    "# تحميل مقياس ROUGE\n",
    "rouge = load(\"rouge\")\n",
    "\n",
    "# قائمة للتخزين\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "# توليد التوقعات\n",
    "for sample in test_dataset:\n",
    "    with torch.no_grad():\n",
    "        # استخدم المفتاح الصحيح: \"input_text\"\n",
    "        inputs = tokenizer(sample[\"input_text\"], return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "        outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "\n",
    "        # فك الترميز\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        ref = sample[\"target_text\"]\n",
    "\n",
    "        predictions.append(pred)\n",
    "        references.append(ref)\n",
    "\n",
    "# حساب ROUGE\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "# عرض النتائج\n",
    "print(\"ROUGE-1:\", results[\"rouge1\"])\n",
    "print(\"ROUGE-2:\", results[\"rouge2\"])\n",
    "print(\"ROUGE-L:\", results[\"rougeL\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaaacb0",
   "metadata": {},
   "source": [
    "ROUGE-1 (~11.7%) بتقيس تطابق الكلمات الفردية → مش سيئة كبداية.\n",
    "\n",
    "ROUGE-2 (~8.3%) بتقيس تطابق الأزواج (bi-grams) → ده أصعب، فالنسبة أقل.\n",
    "\n",
    "ROUGE-L (~11.6%) بتقيس أطول تسلسل مشترك → مؤشر كويس على المحافظة على الترتيب والمعنى العام."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
